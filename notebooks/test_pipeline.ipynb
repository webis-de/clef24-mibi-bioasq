{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from mibi.modules import DocumentsModule, Question\n",
    "from test_utils import (\n",
    "    get_snippets,\n",
    "    PubMedApiRetrieve,\n",
    "    rerank_biencoder,\n",
    "    rerank_crossencoder,\n",
    "    get_snippets,\n",
    "    get_offset,\n",
    "    response_exact_answer,\n",
    "    response_ideal_answer,\n",
    "    flat_list,\n",
    "    get_snippets_blablador,\n",
    "    retrieve_bm25,\n",
    "    remove_stopwords_and_punctuation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['body', 'documents', 'ideal_answer', 'concepts', 'type', 'id', 'snippets'])\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "TEST_FILE = \"../../data/bioasq-data/training12b_new.json\"\n",
    "\n",
    "with open(TEST_FILE, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data = data[\"questions\"][:10]  # for the test purpose, take one instance\n",
    "print(data[0].keys())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRIEVE_TOP_K = 200\n",
    "RERANK_BM25 = 50\n",
    "RERANK_CROSS = 25\n",
    "RERANK_BI = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:48<00:49,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query metformin interfere thyroxine absorption\n",
      "trying new query metformin interfere thyroxine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:31<00:10, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query List human genes encoding dishevelled proteins\n",
      "trying new query List human genes encoding dishevelled\n",
      "trying new query List human genes encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:49<00:00, 11.00s/it]\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    Question(\n",
    "        id=q[\"id\"],\n",
    "        type=q[\"type\"],\n",
    "        body=q[\"body\"],\n",
    "    )\n",
    "    for q in data\n",
    "]\n",
    "retrieve_abstracts = PubMedApiRetrieve(verbose=True, num_results=RETRIEVE_TOP_K)\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    retrieved = retrieve_abstracts.transform([question])\n",
    "    if retrieved.empty:\n",
    "        question.body = remove_stopwords_and_punctuation(question.body)\n",
    "        print(f\"trying new query {question.body}\")\n",
    "        etrieved = retrieve_abstracts.transform([question])\n",
    "\n",
    "    while retrieved.empty:\n",
    "        question.body = \" \".join(question.body.split()[:-1])\n",
    "        print(f\"trying new query {question.body}\")\n",
    "        retrieved = retrieve_abstracts.transform([question])\n",
    "\n",
    "    retrieved[\"bm25\"] = retrieve_bm25(question, retrieved)\n",
    "    reranked = retrieved.sort_values(\"bm25\", ascending=False).head(RERANK_BM25)\n",
    "    # reranked.to_csv(f\"temp/reranked/bm25_{question.id}.csv\", index=False)\n",
    "\n",
    "    reranked[\"cos_sim\"] = rerank_crossencoder(question, reranked)\n",
    "    reranked = reranked.sort_values(\"cos_sim\", ascending=False).head(RERANK_CROSS)\n",
    "    reranked = reranked.drop(\"cos_sim\", axis=1)\n",
    "\n",
    "    reranked[\"cos_sim\"] = rerank_biencoder(question, reranked)\n",
    "    reranked = reranked.sort_values(\"cos_sim\", ascending=False).head(RERANK_BI)\n",
    "\n",
    "    reranked[\"question\"] = [question.body] * len(reranked)\n",
    "    reranked[\"questionno\"] = [question.id] * len(reranked)\n",
    "    reranked[\"questiontype\"] = [question.type] * len(reranked)\n",
    "\n",
    "    reranked.to_csv(f\"temp/reranked/{question.id}.csv\", index=False)\n",
    "    # retrieved.to_csv(f\"temp/reranked/retrieved_{question.id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API for snippets (SKIP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:38<00:00, 19.73s/it]\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "\n",
    "IN_DIR = \"temp/reranked/\"\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR)):\n",
    "    reranked = pd.read_csv(os.path.join(IN_DIR, file))\n",
    "    reranked[\"snippets\"] = reranked.apply(\n",
    "        lambda x: get_snippets(x[\"question\"], x[\"title\"], x[\"text\"]), axis=1\n",
    "    )\n",
    "    reranked[\"title_snippets\"] = [x[0] for x in reranked[\"snippets\"]]\n",
    "    reranked[\"abstract_snippets\"] = [x[1] for x in reranked[\"snippets\"]]\n",
    "    reranked[\"offset_title\"] = reranked.apply(\n",
    "        lambda x: get_offset(x[\"title_snippets\"], x[\"text\"]), axis=1\n",
    "    )\n",
    "    reranked[\"offset_abstract\"] = reranked.apply(\n",
    "        lambda x: get_offset(x[\"abstract_snippets\"], x[\"text\"]), axis=1\n",
    "    )\n",
    "    reranked.to_csv(f\"temp/snippets/openai/{file}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API for answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:11<00:43,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:11<00:00,  7.17s/it]\n"
     ]
    }
   ],
   "source": [
    "ABSTRACTS_FOR_ANSWER = 3\n",
    "\n",
    "COLUMNS_FOR_ANSWER = {\n",
    "    \"openai\": [\"abstract_snippets\", \"title_snippets\"],\n",
    "    \"gpt\": [\"abstract_snippets_gpt\", \"title_snippets_gpt\"],\n",
    "    \"mistral\": [\n",
    "        [\"abstract_snippets_mistral\", \"title_snippets_mistral\"],\n",
    "    ],\n",
    "}\n",
    "\n",
    "choice = \"mistral\"\n",
    "\n",
    "IN_DIR = f\"temp/snippets/{choice}/\"\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR)):\n",
    "    reranked = pd.read_csv(os.path.join(IN_DIR, file))\n",
    "    reranked[\"answer_abstracts_exact\"] = [\n",
    "        response_exact_answer(\n",
    "            reranked[\"question\"].tolist()[0],\n",
    "            reranked[\"questiontype\"].tolist()[0],\n",
    "            \" \".join(reranked[\"text\"].tolist()[:ABSTRACTS_FOR_ANSWER]),\n",
    "        )\n",
    "    ] * len(reranked)\n",
    "    reranked[\"answer_abstracts_ideal\"] = [\n",
    "        response_ideal_answer(\n",
    "            reranked[\"question\"].tolist()[0],\n",
    "            reranked[\"questiontype\"].tolist()[0],\n",
    "            \" \".join(reranked[\"text\"].tolist()[:ABSTRACTS_FOR_ANSWER]),\n",
    "        )\n",
    "    ] * len(reranked)\n",
    "    reranked[\"answer_snippets_exact\"] = [\n",
    "        response_exact_answer(\n",
    "            reranked[\"question\"].tolist()[0],\n",
    "            reranked[\"questiontype\"].tolist()[0],\n",
    "            \"\".join(\n",
    "                flat_list(reranked[COLUMNS_FOR_ANSWER[choice][0][0]].tolist())\n",
    "                + flat_list(reranked[COLUMNS_FOR_ANSWER[choice][0][1]])\n",
    "            ),\n",
    "        )\n",
    "    ] * len(reranked)\n",
    "    reranked[\"answer_snippets_ideal\"] = [\n",
    "        response_ideal_answer(\n",
    "            reranked[\"question\"].tolist()[0],\n",
    "            reranked[\"questiontype\"].tolist()[0],\n",
    "            \"\".join(\n",
    "                flat_list(reranked[COLUMNS_FOR_ANSWER[choice][0][0]].tolist())\n",
    "                + flat_list(reranked[COLUMNS_FOR_ANSWER[choice][0][0]])\n",
    "            ),\n",
    "        )\n",
    "    ] * len(reranked)\n",
    "    reranked.to_csv(f\"temp/answers/openai/{choice}/{file}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_exact_answer(row, ABSTRACTS_OR_SNIPPETS):\n",
    "    if row.questiontype == \"yesno\":\n",
    "        return row[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"][0]\n",
    "    elif row.questiontype == \"summary\":\n",
    "        return row[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"][0]\n",
    "    else:\n",
    "        return row[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"]\n",
    "\n",
    "\n",
    "def return_snippets(reranked, choice):\n",
    "    output = []\n",
    "    for _, row in reranked.iterrows():\n",
    "        is_success = False\n",
    "        if row[f\"abstract_snippets_{choice}\"]:\n",
    "            for i, snippet in enumerate(row[f\"abstract_snippets_{choice}\"]):\n",
    "                try:\n",
    "                    d = {\n",
    "                        \"document\": row[\"url\"],\n",
    "                        \"text\": snippet,\n",
    "                        \"offsetInBeginSection\": row[f\"offset_abstract_{choice}\"][i][0],\n",
    "                        \"offsetInEndSection\": row[f\"offset_abstract_{choice}\"][i][1],\n",
    "                        \"beginSection\": \"abstract\",\n",
    "                        \"endSection\": \"abstract\",\n",
    "                    }\n",
    "                    output.append(d)\n",
    "                    is_success = True\n",
    "                except:\n",
    "                    pass\n",
    "        if not is_success:\n",
    "            if row[f\"title_snippets_{choice}\"]:\n",
    "                for i, snippet in enumerate(row[f\"title_snippets_{choice}\"]):\n",
    "                    try:\n",
    "                        d = {\n",
    "                            \"document\": row[\"url\"],\n",
    "                            \"text\": snippet,\n",
    "                            \"offsetInBeginSection\": row[f\"offset_title_{choice}\"][i][0],\n",
    "                            \"offsetInEndSection\": row[f\"offset_title_{choice}\"][i][1],\n",
    "                            \"beginSection\": \"title\",\n",
    "                            \"endSection\": \"title\",\n",
    "                        }\n",
    "                        output.append(d)\n",
    "                    except:\n",
    "                        pass\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers based on snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 177.12it/s]\n"
     ]
    }
   ],
   "source": [
    "IN_DIR1 = f\"temp/answers/openai/{choice}\"\n",
    "IN_DIR2 = \"temp/snippets/gpt\"\n",
    "IN_DIR3 = \"temp/snippets/mistral\"\n",
    "\n",
    "ABSTRACTS_OR_SNIPPETS = \"snippets\"\n",
    "\n",
    "json_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR1)):\n",
    "    reranked1 = pd.read_csv(os.path.join(IN_DIR1, file))\n",
    "    reranked2 = pd.read_csv(os.path.join(IN_DIR2, file))\n",
    "    reranked3 = pd.read_csv(os.path.join(IN_DIR3, file))\n",
    "    reranked_merged = pd.concat([reranked1, reranked2, reranked3], axis=1)\n",
    "    reranked_merged = reranked_merged.loc[:, ~reranked_merged.columns.duplicated()]\n",
    "    reranked_merged[f\"title_snippets_{choice}\"] = reranked_merged[\n",
    "        f\"title_snippets_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"abstract_snippets_{choice}\"] = reranked_merged[\n",
    "        f\"abstract_snippets_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"offset_title_{choice}\"] = reranked_merged[\n",
    "        f\"offset_title_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"offset_abstract_{choice}\"] = reranked_merged[\n",
    "        f\"offset_abstract_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"] = reranked_merged[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"] = reranked_merged[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    json_list.append(\n",
    "        {\n",
    "            \"type\": reranked_merged[\"questiontype\"].tolist()[0],\n",
    "            \"body\": reranked_merged[\"question\"].tolist()[0],\n",
    "            \"id\": reranked_merged[\"questionno\"].tolist()[0],\n",
    "            \"ideal_answer\": reranked_merged[\n",
    "                f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"\n",
    "            ].tolist()[0][0],\n",
    "            \"exact_answer\": return_exact_answer(\n",
    "                reranked_merged.iloc[0], ABSTRACTS_OR_SNIPPETS\n",
    "            ),\n",
    "            \"documents\": reranked_merged[\"url\"].tolist(),\n",
    "            \"snippets\": return_snippets(reranked_merged, choice),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    json_out = {\"questions\": json_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp/submission/system_1.json\", \"w\") as f:\n",
    "    json.dump(json_out, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers based on abstracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 174.59it/s]\n"
     ]
    }
   ],
   "source": [
    "IN_DIR1 = f\"temp/answers/openai/{choice}\"\n",
    "IN_DIR2 = \"temp/snippets/gpt\"\n",
    "IN_DIR3 = \"temp/snippets/mistral\"\n",
    "\n",
    "ABSTRACTS_OR_SNIPPETS = \"abstracts\"\n",
    "\n",
    "json_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR1)):\n",
    "    reranked1 = pd.read_csv(os.path.join(IN_DIR1, file))\n",
    "    reranked2 = pd.read_csv(os.path.join(IN_DIR2, file))\n",
    "    reranked3 = pd.read_csv(os.path.join(IN_DIR3, file))\n",
    "    reranked_merged = pd.concat([reranked1, reranked2, reranked3], axis=1)\n",
    "    reranked_merged = reranked_merged.loc[:, ~reranked_merged.columns.duplicated()]\n",
    "    reranked_merged[f\"title_snippets_{choice}\"] = reranked_merged[\n",
    "        f\"title_snippets_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"abstract_snippets_{choice}\"] = reranked_merged[\n",
    "        f\"abstract_snippets_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"offset_title_{choice}\"] = reranked_merged[\n",
    "        f\"offset_title_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"offset_abstract_{choice}\"] = reranked_merged[\n",
    "        f\"offset_abstract_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"] = reranked_merged[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"] = reranked_merged[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    json_list.append(\n",
    "        {\n",
    "            \"type\": reranked_merged[\"questiontype\"].tolist()[0],\n",
    "            \"body\": reranked_merged[\"question\"].tolist()[0],\n",
    "            \"id\": reranked_merged[\"questionno\"].tolist()[0],\n",
    "            \"ideal_answer\": reranked_merged[\n",
    "                f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"\n",
    "            ].tolist()[0][0],\n",
    "            \"exact_answer\": return_exact_answer(\n",
    "                reranked_merged.iloc[0], ABSTRACTS_OR_SNIPPETS\n",
    "            ),\n",
    "            \"documents\": reranked_merged[\"url\"].tolist(),\n",
    "            \"snippets\": return_snippets(reranked_merged, choice),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    json_out = {\"questions\": json_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp/submission/system_2.json\", \"w\") as f:\n",
    "    json.dump(json_out, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reranked[\"snippets_blablador_gpt\"] = reranked.apply(\n",
    "#     lambda x: get_snippets_blablador(\n",
    "#         question.body, x[\"title\"], x[\"text\"], model=\"gpt-3.5-turbo\"\n",
    "#     ),\n",
    "#     axis=1,\n",
    "# )\n",
    "# reranked[\"snippets_blablador_mistral\"] = reranked.apply(\n",
    "#     lambda x: get_snippets_blablador(\n",
    "#         question.body, x[\"title\"], x[\"text\"], model=\"Mistral-7B-Instruct-v0.2\"\n",
    "#     ),\n",
    "#     axis=1,\n",
    "# )\n",
    "# reranked[\"title_snippets_gpt\"] = [x[0] for x in reranked[\"snippets_blablador_gpt\"]]\n",
    "# reranked[\"abstract_snippets_gpt\"] = [\n",
    "#     x[1] for x in reranked[\"snippets_blablador_gpt\"]\n",
    "# ]\n",
    "# reranked[\"title_snippets_mistral\"] = [\n",
    "#     x[0] for x in reranked[\"snippets_blablador_mistral\"]\n",
    "# ]\n",
    "# reranked[\"abstract_snippets_mistral\"] = [\n",
    "#     x[1] for x in reranked[\"snippets_blablador_mistral\"]\n",
    "# ]\n",
    "\n",
    "# reranked[\"offset_title_gpt\"] = reranked.apply(\n",
    "#     lambda x: get_offset(x[\"title_snippets_gpt\"], x[\"text\"]), axis=1\n",
    "# )\n",
    "# reranked[\"offset_abstract_gpt\"] = reranked.apply(\n",
    "#     lambda x: get_offset(x[\"abstract_snippets_gpt\"], x[\"text\"]), axis=1\n",
    "# )\n",
    "\n",
    "# reranked[\"offset_title_mistral\"] = reranked.apply(\n",
    "#     lambda x: get_offset(x[\"title_snippets_mistral\"], x[\"text\"]), axis=1\n",
    "# )\n",
    "# reranked[\"offset_abstract_mistral\"] = reranked.apply(\n",
    "#     lambda x: get_offset(x[\"abstract_snippets_mistral\"], x[\"text\"]), axis=1\n",
    "# )\n",
    "\n",
    "\n",
    "# reranked[\"answer_abstracts_exact\"] = [\n",
    "#     response_exact_answer(\n",
    "#         question.body,\n",
    "#         question.type,\n",
    "#         \" \".join(reranked[\"text\"].tolist()[:ABSTRACTS_FOR_ANSWER]),\n",
    "#     )\n",
    "# ] * len(reranked)\n",
    "# reranked[\"answer_abstracts_ideal\"] = [\n",
    "#     response_ideal_answer(\n",
    "#         question.body,\n",
    "#         question.type,\n",
    "#         \" \".join(reranked[\"text\"].tolist()[:ABSTRACTS_FOR_ANSWER]),\n",
    "#     )\n",
    "# ] * len(reranked)\n",
    "# reranked[\"answer_snippets_exact\"] = [\n",
    "#     response_exact_answer(\n",
    "#         question.body,\n",
    "#         question.type,\n",
    "#         \" \".join(\n",
    "#             flat_list(reranked[\"abstract_snippets\"].tolist())\n",
    "#             + flat_list(reranked[\"title_snippets\"])\n",
    "#         ),\n",
    "#     )\n",
    "# ] * len(reranked)\n",
    "# reranked[\"answer_snippets_ideal\"] = [\n",
    "#     response_ideal_answer(\n",
    "#         question.body,\n",
    "#         question.type,\n",
    "#         \" \".join(\n",
    "#             flat_list(reranked[\"abstract_snippets\"].tolist())\n",
    "#             + flat_list(reranked[\"title_snippets\"])\n",
    "#         ),\n",
    "#     )\n",
    "# ] * len(reranked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
