{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from mibi.modules import DocumentsModule, Question\n",
    "from test_utils import (\n",
    "    get_snippets,\n",
    "    PubMedApiRetrieve,\n",
    "    rerank_biencoder,\n",
    "    rerank_crossencoder,\n",
    "    get_snippets,\n",
    "    get_offset,\n",
    "    response_exact_answer,\n",
    "    response_ideal_answer,\n",
    "    flat_list,\n",
    "    get_snippets_blablador,\n",
    "    retrieve_bm25,\n",
    "    remove_stopwords_and_punctuation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'type', 'body'])\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "# Hi Alexander,\n",
    "# thanks for contacting us. Indeed, there was a mistake in the filename, not the contents of the file, which is now fixed.\n",
    "# New file (name) BioASQ-task12bPhaseA-testset1\n",
    "\n",
    "TEST_FILE = \"temp/test_set/BioASQ-task11bPhaseA-testset1\"\n",
    "\n",
    "with open(TEST_FILE, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data = data[\"questions\"]\n",
    "print(data[0].keys())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRIEVE_TOP_K = 200\n",
    "RERANK_BM25 = 50\n",
    "RERANK_CROSS = 25\n",
    "RERANK_BI = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7/85 [00:58<10:26,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query MDMA ecstasy successfully used treat PTSD disorder\n",
      "original question: Has MDMA(ecstasy) been successfully used to treat PTSD disorder?\n",
      "trying new query MDMA ecstasy successfully used treat PTSD\n",
      "original question: Has MDMA(ecstasy) been successfully used to treat PTSD disorder?\n",
      "trying new query MDMA ecstasy successfully used treat\n",
      "original question: Has MDMA(ecstasy) been successfully used to treat PTSD disorder?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 13/85 [02:03<11:28,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query measles immunisation best public health approach reduce incidence measles worldwide\n",
      "original question: Is measles immunisation the best public health approach to reduce incidence of measles worldwide?\n",
      "trying new query measles immunisation best public health approach reduce incidence measles\n",
      "original question: Is measles immunisation the best public health approach to reduce incidence of measles worldwide?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 16/85 [02:29<09:47,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query proportion alteration NTRK genes attributable colorectal cancer\n",
      "original question: What proportion of alteration in NTRK genes are attributable to colorectal cancer?\n",
      "trying new query proportion alteration NTRK genes attributable colorectal\n",
      "original question: What proportion of alteration in NTRK genes are attributable to colorectal cancer?\n",
      "trying new query proportion alteration NTRK genes attributable\n",
      "original question: What proportion of alteration in NTRK genes are attributable to colorectal cancer?\n",
      "trying new query proportion alteration NTRK genes\n",
      "original question: What proportion of alteration in NTRK genes are attributable to colorectal cancer?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 17/85 [02:45<12:25, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query Please list Janus Kinase inhibitors used treat Inflammatory Bowel Disease IBD\n",
      "original question: Please list the Janus Kinase inhibitors used to treat Inflammatory Bowel Disease(IBD)\n",
      "trying new query Please list Janus Kinase inhibitors used treat Inflammatory Bowel Disease\n",
      "original question: Please list the Janus Kinase inhibitors used to treat Inflammatory Bowel Disease(IBD)\n",
      "trying new query Please list Janus Kinase inhibitors used treat Inflammatory Bowel\n",
      "original question: Please list the Janus Kinase inhibitors used to treat Inflammatory Bowel Disease(IBD)\n",
      "trying new query Please list Janus Kinase inhibitors used treat Inflammatory\n",
      "original question: Please list the Janus Kinase inhibitors used to treat Inflammatory Bowel Disease(IBD)\n",
      "trying new query Please list Janus Kinase inhibitors used treat\n",
      "original question: Please list the Janus Kinase inhibitors used to treat Inflammatory Bowel Disease(IBD)\n",
      "trying new query Please list Janus Kinase inhibitors used\n",
      "original question: Please list the Janus Kinase inhibitors used to treat Inflammatory Bowel Disease(IBD)\n",
      "trying new query Please list Janus Kinase inhibitors\n",
      "original question: Please list the Janus Kinase inhibitors used to treat Inflammatory Bowel Disease(IBD)\n",
      "trying new query Please list Janus Kinase\n",
      "original question: Please list the Janus Kinase inhibitors used to treat Inflammatory Bowel Disease(IBD)\n",
      "trying new query Please list Janus\n",
      "original question: Please list the Janus Kinase inhibitors used to treat Inflammatory Bowel Disease(IBD)\n",
      "trying new query Please list\n",
      "original question: Please list the Janus Kinase inhibitors used to treat Inflammatory Bowel Disease(IBD)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 18/85 [03:22<20:46, 18.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query babies young children risk severe malaria endemic areas\n",
      "original question: Are only babies and young children at risk of severe malaria in endemic areas?\n",
      "trying new query babies young children risk severe malaria endemic\n",
      "original question: Are only babies and young children at risk of severe malaria in endemic areas?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 19/85 [03:38<19:36, 17.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query types glucosteroids used management Duchenne muscular dystrophy\n",
      "original question: What types of glucosteroids are used for the management of Duchenne muscular dystrophy?\n",
      "trying new query types glucosteroids used management Duchenne muscular\n",
      "original question: What types of glucosteroids are used for the management of Duchenne muscular dystrophy?\n",
      "trying new query types glucosteroids used management Duchenne\n",
      "original question: What types of glucosteroids are used for the management of Duchenne muscular dystrophy?\n",
      "trying new query types glucosteroids used management\n",
      "original question: What types of glucosteroids are used for the management of Duchenne muscular dystrophy?\n",
      "trying new query types glucosteroids used\n",
      "original question: What types of glucosteroids are used for the management of Duchenne muscular dystrophy?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 21/85 [04:05<16:10, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query oncogene somatic mutations associated situ carcinoma evolution colonic polyp adenomas\n",
      "original question: Which oncogene somatic mutations are associated to in situ carcinoma evolution from colonic polyp adenomas?\n",
      "trying new query oncogene somatic mutations associated situ carcinoma evolution colonic polyp\n",
      "original question: Which oncogene somatic mutations are associated to in situ carcinoma evolution from colonic polyp adenomas?\n",
      "trying new query oncogene somatic mutations associated situ carcinoma evolution colonic\n",
      "original question: Which oncogene somatic mutations are associated to in situ carcinoma evolution from colonic polyp adenomas?\n",
      "trying new query oncogene somatic mutations associated situ carcinoma evolution\n",
      "original question: Which oncogene somatic mutations are associated to in situ carcinoma evolution from colonic polyp adenomas?\n",
      "trying new query oncogene somatic mutations associated situ carcinoma\n",
      "original question: Which oncogene somatic mutations are associated to in situ carcinoma evolution from colonic polyp adenomas?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 25/85 [04:55<11:59, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query medication tested PEMMELA trial\n",
      "original question: What medication were tested in the PEMMELA trial?\n",
      "trying new query medication tested PEMMELA\n",
      "original question: What medication were tested in the PEMMELA trial?\n",
      "trying new query medication tested\n",
      "original question: What medication were tested in the PEMMELA trial?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 26/85 [05:16<14:10, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query pathophysiological mechanism microbiota produce malignant lesions colonic mucosa\n",
      "original question: What is the pathophysiological mechanism by which the microbiota produce malignant lesions in colonic mucosa?\n",
      "trying new query pathophysiological mechanism microbiota produce malignant lesions colonic\n",
      "original question: What is the pathophysiological mechanism by which the microbiota produce malignant lesions in colonic mucosa?\n",
      "trying new query pathophysiological mechanism microbiota produce malignant lesions\n",
      "original question: What is the pathophysiological mechanism by which the microbiota produce malignant lesions in colonic mucosa?\n",
      "trying new query pathophysiological mechanism microbiota produce malignant\n",
      "original question: What is the pathophysiological mechanism by which the microbiota produce malignant lesions in colonic mucosa?\n",
      "trying new query pathophysiological mechanism microbiota produce\n",
      "original question: What is the pathophysiological mechanism by which the microbiota produce malignant lesions in colonic mucosa?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 27/85 [05:39<16:28, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query carotenodermia caused excess lycopene diet\n",
      "original question: is carotenodermia caused by an excess of lycopene in the diet?\n",
      "trying new query carotenodermia caused excess lycopene\n",
      "original question: is carotenodermia caused by an excess of lycopene in the diet?\n",
      "trying new query carotenodermia caused excess\n",
      "original question: is carotenodermia caused by an excess of lycopene in the diet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 28/85 [05:54<15:37, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query two main active ingredients standard PrEP Pre-Exposure Prophylaxis\n",
      "original question: Which are the two main active ingredients of the standard PrEP (Pre-Exposure Prophylaxis)?\n",
      "trying new query two main active ingredients standard PrEP Pre-Exposure\n",
      "original question: Which are the two main active ingredients of the standard PrEP (Pre-Exposure Prophylaxis)?\n",
      "trying new query two main active ingredients standard PrEP\n",
      "original question: Which are the two main active ingredients of the standard PrEP (Pre-Exposure Prophylaxis)?\n",
      "trying new query two main active ingredients standard\n",
      "original question: Which are the two main active ingredients of the standard PrEP (Pre-Exposure Prophylaxis)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 46/85 [08:50<06:30, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query sectoral Heterochromia associated Crohn 's disease\n",
      "original question: Is sectoral Heterochromia associated with Crohn's disease?\n",
      "trying new query sectoral Heterochromia associated Crohn 's\n",
      "original question: Is sectoral Heterochromia associated with Crohn's disease?\n",
      "trying new query sectoral Heterochromia associated Crohn\n",
      "original question: Is sectoral Heterochromia associated with Crohn's disease?\n",
      "trying new query sectoral Heterochromia associated\n",
      "original question: Is sectoral Heterochromia associated with Crohn's disease?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 47/85 [09:07<07:43, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query List effective treatment methods Madelung disease\n",
      "original question: List the most effective treatment methods for Madelung disease.\n",
      "trying new query List effective treatment methods Madelung\n",
      "original question: List the most effective treatment methods for Madelung disease.\n",
      "trying new query List effective treatment methods\n",
      "original question: List the most effective treatment methods for Madelung disease.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 48/85 [09:25<08:38, 14.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query common side effects progesterone-only pill POP\n",
      "original question: What are common side effects of the progesterone-only pill (POP)?\n",
      "trying new query common side effects progesterone-only pill\n",
      "original question: What are common side effects of the progesterone-only pill (POP)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 50/85 [09:43<06:34, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query Explain difference eosinophilic esophagitis reflux-induced esophagitis\n",
      "original question: Explain the difference between eosinophilic esophagitis and reflux-induced esophagitis.\n",
      "trying new query Explain difference eosinophilic esophagitis reflux-induced\n",
      "original question: Explain the difference between eosinophilic esophagitis and reflux-induced esophagitis.\n",
      "trying new query Explain difference eosinophilic esophagitis\n",
      "original question: Explain the difference between eosinophilic esophagitis and reflux-induced esophagitis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 63/85 [11:53<03:06,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query find individual suspect overdosed\n",
      "original question: What should you do if you find an individual that you suspect has overdosed?\n",
      "trying new query find individual suspect\n",
      "original question: What should you do if you find an individual that you suspect has overdosed?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 65/85 [12:18<03:19, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query Please summarize MuSK Antibody positive Myasthenia Gravis\n",
      "original question: Please summarize MuSK Antibody positive Myasthenia Gravis.\n",
      "trying new query Please summarize MuSK Antibody positive Myasthenia\n",
      "original question: Please summarize MuSK Antibody positive Myasthenia Gravis.\n",
      "trying new query Please summarize MuSK Antibody positive\n",
      "original question: Please summarize MuSK Antibody positive Myasthenia Gravis.\n",
      "trying new query Please summarize MuSK Antibody\n",
      "original question: Please summarize MuSK Antibody positive Myasthenia Gravis.\n",
      "trying new query Please summarize MuSK\n",
      "original question: Please summarize MuSK Antibody positive Myasthenia Gravis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 66/85 [12:36<03:59, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query advisable bring fever supposedly meant assist fight disease\n",
      "original question: Is it advisable to bring the fever down when it is supposedly meant to assist in the fight of disease?\n",
      "trying new query advisable bring fever supposedly meant assist fight\n",
      "original question: Is it advisable to bring the fever down when it is supposedly meant to assist in the fight of disease?\n",
      "trying new query advisable bring fever supposedly meant assist\n",
      "original question: Is it advisable to bring the fever down when it is supposedly meant to assist in the fight of disease?\n",
      "trying new query advisable bring fever supposedly meant\n",
      "original question: Is it advisable to bring the fever down when it is supposedly meant to assist in the fight of disease?\n",
      "trying new query advisable bring fever supposedly\n",
      "original question: Is it advisable to bring the fever down when it is supposedly meant to assist in the fight of disease?\n",
      "trying new query advisable bring fever\n",
      "original question: Is it advisable to bring the fever down when it is supposedly meant to assist in the fight of disease?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 77/85 [14:28<01:14,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query Please list congenital fibrinogen disorders\n",
      "original question: Please list the congenital fibrinogen disorders.\n",
      "trying new query Please list congenital fibrinogen\n",
      "original question: Please list the congenital fibrinogen disorders.\n",
      "trying new query Please list congenital\n",
      "original question: Please list the congenital fibrinogen disorders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 79/85 [14:52<01:02, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query administration route zavegepant\n",
      "original question: What is the administration route of zavegepant?\n",
      "trying new query administration route\n",
      "original question: What is the administration route of zavegepant?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 80/85 [15:07<00:59, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query Brunner 's gland hamartoma BGH often asymptomatic usually diagnosed\n",
      "original question: Brunner's gland hamartoma (BGH) is often asymptomatic and so how is it usually diagnosed?\n",
      "trying new query Brunner 's gland hamartoma BGH often asymptomatic usually\n",
      "original question: Brunner's gland hamartoma (BGH) is often asymptomatic and so how is it usually diagnosed?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 81/85 [15:18<00:46, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying new query peritoneal dialysis best option infants kidney failure\n",
      "original question: Is peritoneal dialysis the best option for infants with kidney failure?\n",
      "trying new query peritoneal dialysis best option infants kidney\n",
      "original question: Is peritoneal dialysis the best option for infants with kidney failure?\n",
      "trying new query peritoneal dialysis best option infants\n",
      "original question: Is peritoneal dialysis the best option for infants with kidney failure?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [16:01<00:00, 11.31s/it]\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    Question(\n",
    "        id=q[\"id\"],\n",
    "        type=q[\"type\"],\n",
    "        body=q[\"body\"],\n",
    "    )\n",
    "    for q in data\n",
    "]\n",
    "retrieve_abstracts = PubMedApiRetrieve(verbose=True, num_results=RETRIEVE_TOP_K)\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    retrieved = retrieve_abstracts.transform([question])\n",
    "    if retrieved.empty:\n",
    "        question_new = copy.deepcopy(question)\n",
    "        question_new.body = remove_stopwords_and_punctuation(question_new.body)\n",
    "        print(f\"trying new query {question_new.body}\")\n",
    "        print(f\"original question: {question.body}\")\n",
    "        etrieved = retrieve_abstracts.transform([question_new])\n",
    "\n",
    "    while retrieved.empty:\n",
    "        question_new.body = \" \".join(question_new.body.split()[:-1])\n",
    "        print(f\"trying new query {question_new.body}\")\n",
    "        print(f\"original question: {question.body}\")\n",
    "        retrieved = retrieve_abstracts.transform([question_new])\n",
    "\n",
    "    retrieved[\"bm25\"] = retrieve_bm25(question, retrieved)\n",
    "    reranked = retrieved.sort_values(\"bm25\", ascending=False).head(RERANK_BM25)\n",
    "    # reranked.to_csv(f\"temp/reranked/bm25_{question.id}.csv\", index=False)\n",
    "\n",
    "    reranked[\"cos_sim\"] = rerank_crossencoder(question, reranked)\n",
    "    reranked = reranked.sort_values(\"cos_sim\", ascending=False).head(RERANK_CROSS)\n",
    "    reranked = reranked.drop(\"cos_sim\", axis=1)\n",
    "\n",
    "    reranked[\"cos_sim\"] = rerank_biencoder(question, reranked)\n",
    "    reranked = reranked.sort_values(\"cos_sim\", ascending=False).head(RERANK_BI)\n",
    "\n",
    "    reranked[\"question\"] = [question.body] * len(reranked)\n",
    "    reranked[\"questionno\"] = [question.id] * len(reranked)\n",
    "    reranked[\"questiontype\"] = [question.type] * len(reranked)\n",
    "\n",
    "    reranked.to_csv(f\"temp/reranked/{question.id}.csv\", index=False)\n",
    "    # retrieved.to_csv(f\"temp/reranked/retrieved_{question.id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API for snippets (SKIP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:38<00:00, 19.73s/it]\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "\n",
    "IN_DIR = \"temp/reranked/\"\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR)):\n",
    "    reranked = pd.read_csv(os.path.join(IN_DIR, file))\n",
    "    reranked[\"snippets\"] = reranked.apply(\n",
    "        lambda x: get_snippets(x[\"question\"], x[\"title\"], x[\"text\"]), axis=1\n",
    "    )\n",
    "    reranked[\"title_snippets\"] = [x[0] for x in reranked[\"snippets\"]]\n",
    "    reranked[\"abstract_snippets\"] = [x[1] for x in reranked[\"snippets\"]]\n",
    "    reranked[\"offset_title\"] = reranked.apply(\n",
    "        lambda x: get_offset(x[\"title_snippets\"], x[\"text\"]), axis=1\n",
    "    )\n",
    "    reranked[\"offset_abstract\"] = reranked.apply(\n",
    "        lambda x: get_offset(x[\"abstract_snippets\"], x[\"text\"]), axis=1\n",
    "    )\n",
    "    reranked.to_csv(f\"temp/snippets/openai/{file}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API for answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = \"pyterrier\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTerrier snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 14/85 [00:44<03:26,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 24/85 [01:14<02:49,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 25/85 [01:18<03:20,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 27/85 [01:24<02:46,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 30/85 [01:31<02:28,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 37/85 [01:55<02:10,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 74/85 [03:52<00:40,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [04:35<00:00,  3.24s/it]\n"
     ]
    }
   ],
   "source": [
    "IN_DIR = f\"temp/batch_2/snippets/{choice}/\"\n",
    "# OUT_DIR = f\"temp/batch_2/answers/openai/{choice}/\"\n",
    "\n",
    "processed_files = os.listdir(\"temp/batch_2/answers/openai/pyterrier_snippets/\")\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR)):\n",
    "    if file not in processed_files:\n",
    "        reranked = pd.read_csv(os.path.join(IN_DIR, file))\n",
    "\n",
    "        reranked[\"answer_snippets_exact\"] = [\n",
    "            response_exact_answer(\n",
    "                reranked[\"question\"].tolist()[0],\n",
    "                reranked[\"questiontype\"].tolist()[0],\n",
    "                \" \".join(reranked[\"text\"].tolist()),\n",
    "            )\n",
    "        ] * len(reranked)\n",
    "        reranked[\"answer_snippets_ideal\"] = [\n",
    "            response_ideal_answer(\n",
    "                reranked[\"question\"].tolist()[0],\n",
    "                reranked[\"questiontype\"].tolist()[0],\n",
    "                \" \".join(reranked[\"text\"].tolist()),\n",
    "            )\n",
    "        ] * len(reranked)\n",
    "        reranked.to_csv(\n",
    "            f\"temp/batch_2/answers/openai/pyterrier_snippets/{file}\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTerrier abstracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 8/85 [00:30<05:28,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 18/85 [01:06<03:48,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 24/85 [01:25<02:52,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 55/85 [03:04<01:20,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 75/85 [04:04<00:28,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 76/85 [04:09<00:32,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [04:37<00:00,  3.27s/it]\n"
     ]
    }
   ],
   "source": [
    "IN_DIR = f\"temp/batch_2/reranked/{choice}/\"\n",
    "processed_files = os.listdir(\"temp/batch_2/answers/openai/pyterrier_docs/\")\n",
    "\n",
    "ABSTRACTS_FOR_ANSWER = 3\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR)):\n",
    "    if file not in processed_files:\n",
    "        reranked = pd.read_csv(os.path.join(IN_DIR, file))\n",
    "\n",
    "        reranked[\"answer_abstracts_exact\"] = [\n",
    "            response_exact_answer(\n",
    "                reranked[\"question\"].tolist()[0],\n",
    "                reranked[\"questiontype\"].tolist()[0],\n",
    "                \" \".join(\n",
    "                    [a for a in reranked[\"abstract\"].tolist() if str(a) != \"nan\"][\n",
    "                        :ABSTRACTS_FOR_ANSWER\n",
    "                    ]\n",
    "                ),\n",
    "            )\n",
    "        ] * len(reranked)\n",
    "        reranked[\"answer_abstracts_ideal\"] = [\n",
    "            response_ideal_answer(\n",
    "                reranked[\"question\"].tolist()[0],\n",
    "                reranked[\"questiontype\"].tolist()[0],\n",
    "                \" \".join(\n",
    "                    [a for a in reranked[\"abstract\"].tolist() if str(a) != \"nan\"][\n",
    "                        :ABSTRACTS_FOR_ANSWER\n",
    "                    ]\n",
    "                ),\n",
    "            )\n",
    "        ] * len(reranked)\n",
    "        reranked.to_csv(\n",
    "            f\"temp/batch_2/answers/openai/pyterrier_docs/{file}\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 81/85 [00:29<00:02,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:03<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "ABSTRACTS_FOR_ANSWER = 3\n",
    "\n",
    "COLUMNS_FOR_ANSWER = {\n",
    "    \"openai\": [\"abstract_snippets\", \"title_snippets\"],\n",
    "    \"gpt\": [\"abstract_snippets_gpt\", \"title_snippets_gpt\"],\n",
    "    \"mistral\": [\n",
    "        [\"abstract_snippets_mistral\", \"title_snippets_mistral\"],\n",
    "    ],\n",
    "}\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR)):\n",
    "    if file not in processed_files:\n",
    "        reranked = pd.read_csv(os.path.join(IN_DIR, file))\n",
    "\n",
    "        reranked[\"answer_abstracts_exact\"] = [\n",
    "            response_exact_answer(\n",
    "                reranked[\"question\"].tolist()[0],\n",
    "                reranked[\"questiontype\"].tolist()[0],\n",
    "                \" \".join(\n",
    "                    [a for a in reranked[\"text\"].tolist() if str(a) != \"nan\"][\n",
    "                        :ABSTRACTS_FOR_ANSWER\n",
    "                    ]\n",
    "                ),\n",
    "            )\n",
    "        ] * len(reranked)\n",
    "        reranked[\"answer_abstracts_ideal\"] = [\n",
    "            response_ideal_answer(\n",
    "                reranked[\"question\"].tolist()[0],\n",
    "                reranked[\"questiontype\"].tolist()[0],\n",
    "                \" \".join(\n",
    "                    [a for a in reranked[\"text\"].tolist() if str(a) != \"nan\"][\n",
    "                        :ABSTRACTS_FOR_ANSWER\n",
    "                    ]\n",
    "                ),\n",
    "            )\n",
    "        ] * len(reranked)\n",
    "        reranked[\"answer_snippets_exact\"] = [\n",
    "            response_exact_answer(\n",
    "                reranked[\"question\"].tolist()[0],\n",
    "                reranked[\"questiontype\"].tolist()[0],\n",
    "                \"\".join(\n",
    "                    flat_list(reranked[COLUMNS_FOR_ANSWER[choice][0][0]].tolist())\n",
    "                    + flat_list(reranked[COLUMNS_FOR_ANSWER[choice][0][1]].tolist())\n",
    "                ),\n",
    "            )\n",
    "        ] * len(reranked)\n",
    "        reranked[\"answer_snippets_ideal\"] = [\n",
    "            response_ideal_answer(\n",
    "                reranked[\"question\"].tolist()[0],\n",
    "                reranked[\"questiontype\"].tolist()[0],\n",
    "                \"\".join(\n",
    "                    flat_list(reranked[COLUMNS_FOR_ANSWER[choice][0][0]].tolist())\n",
    "                    + flat_list(reranked[COLUMNS_FOR_ANSWER[choice][0][1]].tolist())\n",
    "                ),\n",
    "            )\n",
    "        ] * len(reranked)\n",
    "        reranked.to_csv(f\"temp/answers/openai/{choice}/{file}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for PyTerrier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answers based on snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_exact_answer(row, ABSTRACTS_OR_SNIPPETS):\n",
    "    if row.questiontype == \"yesno\":\n",
    "        return row[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"][0]\n",
    "    elif row.questiontype == \"summary\":\n",
    "        return row[f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"][0]\n",
    "    else:\n",
    "        return row[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"]\n",
    "\n",
    "\n",
    "def return_snippets(reranked):\n",
    "    output = []\n",
    "    for _, row in reranked.iterrows():\n",
    "        d = {\n",
    "            \"document\": row[\"url\"],\n",
    "            \"text\": row[\"text\"],\n",
    "            \"offsetInBeginSection\": row[\"snippet_offset_in_begin_section\"],\n",
    "            \"offsetInEndSection\": row[\"snippet_offset_in_end_section\"],\n",
    "            \"beginSection\": row[\"snippet_begin_section\"],\n",
    "            \"endSection\": row[\"snippet_end_section\"],\n",
    "        }\n",
    "        output.append(d)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def fix_list(l):\n",
    "    l_out = []\n",
    "    for item in l:\n",
    "        if type(item) == list:\n",
    "            if len(item) == 1 and [item] not in l_out:\n",
    "                l_out.append(item)\n",
    "            elif len(item) > 1:\n",
    "                for subitem in item:\n",
    "                    if [subitem] not in l_out:\n",
    "                        l_out.append([subitem])\n",
    "        if type(item) == str and [item] not in l_out:\n",
    "            l_out.append([item])\n",
    "\n",
    "    return l_out[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:00<00:00, 489.74it/s]\n"
     ]
    }
   ],
   "source": [
    "IN_DIR1 = \"temp/batch_2/answers/openai/pyterrier_snippets/\"\n",
    "IN_DIR2 = \"temp/batch_2/reranked/pyterrier/\"\n",
    "\n",
    "ABSTRACTS_OR_SNIPPETS = \"snippets\"\n",
    "\n",
    "json_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR1)):\n",
    "    reranked1 = pd.read_csv(os.path.join(IN_DIR1, file))\n",
    "    # reranked2 = pd.read_csv(os.path.join(IN_DIR2, file))\n",
    "    reranked1[f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"] = reranked1[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked1[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"] = reranked1[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"\n",
    "    ].apply(ast.literal_eval)\n",
    "\n",
    "    if reranked1[\"questiontype\"].tolist()[0] in (\"factoid\", \"list\"):\n",
    "        exact_answer = fix_list(\n",
    "            return_exact_answer(reranked1.iloc[0], ABSTRACTS_OR_SNIPPETS)\n",
    "        )\n",
    "    else:\n",
    "        exact_answer = return_exact_answer(reranked1.iloc[0], ABSTRACTS_OR_SNIPPETS)\n",
    "    json_list.append(\n",
    "        {\n",
    "            \"type\": reranked1[\"questiontype\"].tolist()[0],\n",
    "            \"body\": reranked1[\"question\"].tolist()[0],\n",
    "            \"id\": reranked1[\"questionno\"].tolist()[0],\n",
    "            \"ideal_answer\": reranked1[f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"].tolist()[\n",
    "                0\n",
    "            ][0],\n",
    "            \"exact_answer\": exact_answer,\n",
    "            # \"documents\": reranked2[\"url\"].tolist(),\n",
    "            # \"snippets\": return_snippets(reranked1),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    json_out = {\"questions\": json_list}\n",
    "\n",
    "with open(\"temp/batch_2/submission/mibi_rag_snippet.json\", \"w\") as f:\n",
    "    json.dump(json_out, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers based on abstracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:00<00:00, 542.30it/s]\n"
     ]
    }
   ],
   "source": [
    "IN_DIR1 = \"temp/batch_2/answers/openai/pyterrier_docs/\"\n",
    "\n",
    "ABSTRACTS_OR_SNIPPETS = \"abstracts\"\n",
    "\n",
    "json_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR1)):\n",
    "    reranked1 = pd.read_csv(os.path.join(IN_DIR1, file))\n",
    "    # reranked2 = pd.read_csv(os.path.join(IN_DIR2, file))\n",
    "    reranked1[f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"] = reranked1[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked1[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"] = reranked1[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"\n",
    "    ].apply(ast.literal_eval)\n",
    "\n",
    "    if reranked1[\"questiontype\"].tolist()[0] in (\"factoid\", \"list\"):\n",
    "        exact_answer = fix_list(\n",
    "            return_exact_answer(reranked1.iloc[0], ABSTRACTS_OR_SNIPPETS)\n",
    "        )\n",
    "    else:\n",
    "        exact_answer = return_exact_answer(reranked1.iloc[0], ABSTRACTS_OR_SNIPPETS)\n",
    "    json_list.append(\n",
    "        {\n",
    "            \"type\": reranked1[\"questiontype\"].tolist()[0],\n",
    "            \"body\": reranked1[\"question\"].tolist()[0],\n",
    "            \"id\": reranked1[\"questionno\"].tolist()[0],\n",
    "            \"ideal_answer\": reranked1[f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"].tolist()[\n",
    "                0\n",
    "            ][0],\n",
    "            \"exact_answer\": exact_answer,\n",
    "            # \"documents\": reranked1[\"url\"].tolist(),\n",
    "            # \"snippets\": return_snippets(reranked1),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    json_out = {\"questions\": json_list}\n",
    "\n",
    "with open(\"temp/batch_2/submission/mibi_rag_abstract.json\", \"w\") as f:\n",
    "    json.dump(json_out, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_exact_answer(row, ABSTRACTS_OR_SNIPPETS):\n",
    "    if row.questiontype == \"yesno\":\n",
    "        return row[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"][0]\n",
    "    elif row.questiontype == \"summary\":\n",
    "        return row[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"][0]\n",
    "    else:\n",
    "        return row[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"]\n",
    "\n",
    "\n",
    "def return_snippets(reranked, choice):\n",
    "    output = []\n",
    "    for _, row in reranked.iterrows():\n",
    "        is_success = False\n",
    "        if row[f\"abstract_snippets_{choice}\"]:\n",
    "            for i, snippet in enumerate(row[f\"abstract_snippets_{choice}\"]):\n",
    "                try:\n",
    "                    d = {\n",
    "                        \"document\": row[\"url\"],\n",
    "                        \"text\": snippet,\n",
    "                        \"offsetInBeginSection\": row[f\"offset_abstract_{choice}\"][i][0],\n",
    "                        \"offsetInEndSection\": row[f\"offset_abstract_{choice}\"][i][1],\n",
    "                        \"beginSection\": \"abstract\",\n",
    "                        \"endSection\": \"abstract\",\n",
    "                    }\n",
    "                    output.append(d)\n",
    "                    is_success = True\n",
    "                except:\n",
    "                    pass\n",
    "        if not is_success:\n",
    "            if row[f\"title_snippets_{choice}\"]:\n",
    "                for i, snippet in enumerate(row[f\"title_snippets_{choice}\"]):\n",
    "                    try:\n",
    "                        d = {\n",
    "                            \"document\": row[\"url\"],\n",
    "                            \"text\": snippet,\n",
    "                            \"offsetInBeginSection\": row[f\"offset_title_{choice}\"][i][0],\n",
    "                            \"offsetInEndSection\": row[f\"offset_title_{choice}\"][i][1],\n",
    "                            \"beginSection\": \"title\",\n",
    "                            \"endSection\": \"title\",\n",
    "                        }\n",
    "                        output.append(d)\n",
    "                    except:\n",
    "                        pass\n",
    "    return output\n",
    "\n",
    "\n",
    "def fix_list(l):\n",
    "    l_out = []\n",
    "    for item in l:\n",
    "        if type(item) == list:\n",
    "            if len(item) == 1 and [item] not in l_out:\n",
    "                l_out.append(item)\n",
    "            elif len(item) > 1:\n",
    "                for subitem in item:\n",
    "                    if [subitem] not in l_out:\n",
    "                        l_out.append([subitem])\n",
    "        if type(item) == str and [item] not in l_out:\n",
    "            l_out.append([item])\n",
    "\n",
    "    return l_out[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers based on snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:00<00:00, 243.02it/s]\n"
     ]
    }
   ],
   "source": [
    "IN_DIR1 = f\"temp/answers/openai/{choice}\"\n",
    "IN_DIR2 = \"temp/snippets/gpt\"\n",
    "IN_DIR3 = \"temp/snippets/mistral\"\n",
    "\n",
    "ABSTRACTS_OR_SNIPPETS = \"snippets\"\n",
    "\n",
    "json_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR1)):\n",
    "    reranked1 = pd.read_csv(os.path.join(IN_DIR1, file))\n",
    "    # reranked2 = pd.read_csv(os.path.join(IN_DIR2, file))\n",
    "    reranked3 = pd.read_csv(os.path.join(IN_DIR3, file))\n",
    "    # reranked_merged = pd.concat([reranked1, reranked2, reranked3], axis=1)\n",
    "    reranked_merged = pd.concat([reranked1, reranked3], axis=1)\n",
    "    reranked_merged = reranked_merged.loc[:, ~reranked_merged.columns.duplicated()]\n",
    "    reranked_merged[f\"title_snippets_{choice}\"] = reranked_merged[\n",
    "        f\"title_snippets_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"abstract_snippets_{choice}\"] = reranked_merged[\n",
    "        f\"abstract_snippets_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"offset_title_{choice}\"] = reranked_merged[\n",
    "        f\"offset_title_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"offset_abstract_{choice}\"] = reranked_merged[\n",
    "        f\"offset_abstract_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"] = reranked_merged[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"] = reranked_merged[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"\n",
    "    ].apply(ast.literal_eval)\n",
    "\n",
    "    if reranked_merged[\"questiontype\"].tolist()[0] in (\"factoid\", \"list\"):\n",
    "        exact_answer = fix_list(\n",
    "            return_exact_answer(reranked_merged.iloc[0], ABSTRACTS_OR_SNIPPETS)\n",
    "        )\n",
    "    else:\n",
    "        exact_answer = return_exact_answer(\n",
    "            reranked_merged.iloc[0], ABSTRACTS_OR_SNIPPETS\n",
    "        )\n",
    "    json_list.append(\n",
    "        {\n",
    "            \"type\": reranked_merged[\"questiontype\"].tolist()[0],\n",
    "            \"body\": reranked_merged[\"question\"].tolist()[0],\n",
    "            \"id\": reranked_merged[\"questionno\"].tolist()[0],\n",
    "            \"ideal_answer\": reranked_merged[\n",
    "                f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"\n",
    "            ].tolist()[0][0],\n",
    "            \"exact_answer\": exact_answer,\n",
    "            \"documents\": reranked_merged[\"url\"].tolist(),\n",
    "            \"snippets\": return_snippets(reranked_merged, choice)[:10],  # not good\n",
    "        }\n",
    "    )\n",
    "\n",
    "    json_out = {\"questions\": json_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp/submission/system_1.json\", \"w\") as f:\n",
    "    json.dump(json_out, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers based on abstracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:00<00:00, 214.13it/s]\n"
     ]
    }
   ],
   "source": [
    "IN_DIR1 = f\"temp/answers/openai/{choice}\"\n",
    "IN_DIR2 = \"temp/snippets/gpt\"\n",
    "IN_DIR3 = \"temp/snippets/mistral\"\n",
    "\n",
    "ABSTRACTS_OR_SNIPPETS = \"abstracts\"\n",
    "\n",
    "json_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(IN_DIR1)):\n",
    "    reranked1 = pd.read_csv(os.path.join(IN_DIR1, file))\n",
    "    # reranked2 = pd.read_csv(os.path.join(IN_DIR2, file))\n",
    "    reranked3 = pd.read_csv(os.path.join(IN_DIR3, file))\n",
    "    # reranked_merged = pd.concat([reranked1, reranked2, reranked3], axis=1)\n",
    "    reranked_merged = pd.concat([reranked1, reranked3], axis=1)\n",
    "    reranked_merged = reranked_merged.loc[:, ~reranked_merged.columns.duplicated()]\n",
    "    reranked_merged[f\"title_snippets_{choice}\"] = reranked_merged[\n",
    "        f\"title_snippets_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"abstract_snippets_{choice}\"] = reranked_merged[\n",
    "        f\"abstract_snippets_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"offset_title_{choice}\"] = reranked_merged[\n",
    "        f\"offset_title_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"offset_abstract_{choice}\"] = reranked_merged[\n",
    "        f\"offset_abstract_{choice}\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"] = reranked_merged[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"\n",
    "    ].apply(ast.literal_eval)\n",
    "    reranked_merged[f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"] = reranked_merged[\n",
    "        f\"answer_{ABSTRACTS_OR_SNIPPETS}_exact\"\n",
    "    ].apply(ast.literal_eval)\n",
    "\n",
    "    if reranked_merged[\"questiontype\"].tolist()[0] in (\"factoid\", \"list\"):\n",
    "        exact_answer = fix_list(\n",
    "            return_exact_answer(reranked_merged.iloc[0], ABSTRACTS_OR_SNIPPETS)\n",
    "        )\n",
    "    else:\n",
    "        exact_answer = return_exact_answer(\n",
    "            reranked_merged.iloc[0], ABSTRACTS_OR_SNIPPETS\n",
    "        )\n",
    "\n",
    "    json_list.append(\n",
    "        {\n",
    "            \"type\": reranked_merged[\"questiontype\"].tolist()[0],\n",
    "            \"body\": reranked_merged[\"question\"].tolist()[0],\n",
    "            \"id\": reranked_merged[\"questionno\"].tolist()[0],\n",
    "            \"ideal_answer\": reranked_merged[\n",
    "                f\"answer_{ABSTRACTS_OR_SNIPPETS}_ideal\"\n",
    "            ].tolist()[0][0],\n",
    "            \"exact_answer\": exact_answer,\n",
    "            \"documents\": reranked_merged[\"url\"].tolist(),\n",
    "            \"snippets\": return_snippets(reranked_merged, choice)[:10],  # not good\n",
    "        }\n",
    "    )\n",
    "\n",
    "    json_out = {\"questions\": json_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp/submission/system_2.json\", \"w\") as f:\n",
    "    json.dump(json_out, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['documents', 'snippets', 'id', 'type', 'body'])\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "TEST_FILE = \"temp/test_set/BioASQ-task12bPhaseB-testset1\"\n",
    "\n",
    "with open(TEST_FILE, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data = data[\"questions\"]\n",
    "print(data[0].keys())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snippets_from_df(row):\n",
    "    return [x[\"text\"] for x in row.snippets]\n",
    "\n",
    "\n",
    "def fix_list(l):\n",
    "    l_out = []\n",
    "    for item in l:\n",
    "        if type(item) == list:\n",
    "            if len(item) == 1 and [item] not in l_out:\n",
    "                l_out.append(item)\n",
    "            elif len(item) > 1:\n",
    "                for subitem in item:\n",
    "                    if [subitem] not in l_out:\n",
    "                        l_out.append([subitem])\n",
    "        if type(item) == str and [item] not in l_out:\n",
    "            l_out.append([item])\n",
    "\n",
    "    return l_out[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers based on snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 3/85 [00:08<04:01,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 21/85 [01:06<02:26,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 27/85 [01:27<03:11,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 63/85 [03:15<00:58,  2.68s/it]Incomplete output detected, should increase max_tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way (exact answer)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 70/85 [04:03<00:55,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [04:47<00:00,  3.39s/it]\n"
     ]
    }
   ],
   "source": [
    "for d in tqdm(data):\n",
    "    df = pd.json_normalize(d)\n",
    "    df[\"snippets_extracted\"] = df.apply(get_snippets_from_df, axis=1)\n",
    "    df.rename(\n",
    "        columns={\"body\": \"question\", \"id\": \"questionno\", \"type\": \"questiontype\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    df[\"answer_snippets_exact\"] = [\n",
    "        response_exact_answer(\n",
    "            df[\"question\"].values[0],\n",
    "            df[\"questiontype\"].values[0],\n",
    "            \" \".join(df.snippets_extracted.tolist()[0]),\n",
    "        )\n",
    "    ] * len(df)\n",
    "    df[\"answer_snippets_ideal\"] = [\n",
    "        response_ideal_answer(\n",
    "            df[\"question\"].values[0],\n",
    "            df[\"questiontype\"].values[0],\n",
    "            \" \".join(df.snippets_extracted.tolist()[0]),\n",
    "        )\n",
    "    ] * len(df)\n",
    "\n",
    "    df.to_csv(\n",
    "        f\"temp/phase_b/answers/openai/snippets/{df.questionno.values[0]}.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "\n",
    "IN_DIR = \"temp/phase_b/answers/openai/snippets/\"\n",
    "\n",
    "for file in os.listdir(IN_DIR):\n",
    "    df = pd.read_csv(os.path.join(IN_DIR, file))\n",
    "    df[\"answer_snippets_exact\"] = df[\"answer_snippets_exact\"].apply(ast.literal_eval)\n",
    "    df[\"answer_snippets_ideal\"] = df[\"answer_snippets_ideal\"].apply(ast.literal_eval)\n",
    "\n",
    "    if df[\"questiontype\"].values[0] == \"summary\":\n",
    "        json_list.append(\n",
    "            {\n",
    "                \"type\": df[\"questiontype\"].values[0],\n",
    "                \"body\": df[\"question\"].values[0],\n",
    "                \"id\": df[\"questionno\"].values[0],\n",
    "                \"ideal_answer\": df[\"answer_snippets_ideal\"].values[0][0],\n",
    "                \"documents\": df[\"documents\"].apply(ast.literal_eval).tolist()[0],\n",
    "                \"snippets\": df[\"snippets\"].apply(ast.literal_eval).tolist()[0],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        if df[\"questiontype\"].values[0] in (\"factoid\", \"list\"):\n",
    "            exact_answer = fix_list(df[\"answer_snippets_exact\"].values[0])\n",
    "        else:\n",
    "            exact_answer = df[\"answer_snippets_exact\"].values[0][0]\n",
    "\n",
    "        json_list.append(\n",
    "            {\n",
    "                \"type\": df[\"questiontype\"].values[0],\n",
    "                \"body\": df[\"question\"].values[0],\n",
    "                \"id\": df[\"questionno\"].values[0],\n",
    "                \"ideal_answer\": df[\"answer_snippets_ideal\"].values[0][0],\n",
    "                \"exact_answer\": exact_answer,\n",
    "                \"documents\": df[\"documents\"].apply(ast.literal_eval).tolist()[0],\n",
    "                \"snippets\": df[\"snippets\"].apply(ast.literal_eval).tolist()[0],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    json_out = {\"questions\": json_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp/phase_b/submission/system_1.json\", \"w\") as f:\n",
    "    json.dump(json_out, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in json_list:\n",
    "#     try:\n",
    "#         print(d[\"exact_answer\"])\n",
    "#     except:\n",
    "#         print(\"NO ANSWER\")\n",
    "#     print(d[\"ideal_answer\"])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers based on abstracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RERANK_CROSS = 25\n",
    "RERANK_BI = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/85 [00:00<?, ?it/s]/home/bondarenko/laptop/Leipzig/project/mibi-bioasq/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "  4%|▎         | 3/85 [00:35<15:35, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 12/85 [02:41<17:33, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 27/85 [05:56<12:55, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 32/85 [07:07<12:39, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 70/85 [15:42<02:55, 11.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 78/85 [17:39<01:53, 16.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 83/85 [18:56<00:31, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying another way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [19:28<00:00, 13.75s/it]\n"
     ]
    }
   ],
   "source": [
    "from get_pubmed_documents import get_title_abstract\n",
    "\n",
    "ABSTRACTS_FOR_ANSWER = 3\n",
    "\n",
    "for d in tqdm(data):\n",
    "    df = pd.json_normalize(d)\n",
    "    df[\"snippets_extracted\"] = df.apply(get_snippets_from_df, axis=1)\n",
    "    df.rename(\n",
    "        columns={\"body\": \"question\", \"id\": \"questionno\", \"type\": \"questiontype\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    titles_abstracts = [get_title_abstract(url) for url in df[\"documents\"].tolist()[0]]\n",
    "    titles = list(zip(*titles_abstracts))[0]\n",
    "    abstracts = list(zip(*titles_abstracts))[1]\n",
    "    reranked = pd.DataFrame({\"title\": titles, \"abstract\": abstracts})\n",
    "    question = Question(\n",
    "        id=df[\"questionno\"].values[0],\n",
    "        type=df[\"questiontype\"].values[0],\n",
    "        body=df[\"question\"].values[0],\n",
    "    )\n",
    "\n",
    "    reranked = pd.DataFrame({\"title\": titles, \"text\": abstracts})\n",
    "    reranked[\"cos_sim\"] = rerank_crossencoder(question, reranked)\n",
    "    reranked = reranked.sort_values(\"cos_sim\", ascending=False).head(RERANK_CROSS)\n",
    "    reranked = reranked.drop(\"cos_sim\", axis=1)\n",
    "\n",
    "    reranked[\"cos_sim\"] = rerank_biencoder(question, reranked)\n",
    "    reranked = reranked.sort_values(\"cos_sim\", ascending=False).head(RERANK_BI)\n",
    "\n",
    "    df[\"answer_abstracts_exact\"] = [\n",
    "        response_exact_answer(\n",
    "            df[\"question\"].values[0],\n",
    "            df[\"questiontype\"].values[0],\n",
    "            \" \".join(reranked[\"text\"].tolist()[:ABSTRACTS_FOR_ANSWER]),\n",
    "        )\n",
    "    ] * len(df)\n",
    "    df[\"answer_abstracts_ideal\"] = [\n",
    "        response_ideal_answer(\n",
    "            df[\"question\"].values[0],\n",
    "            df[\"questiontype\"].values[0],\n",
    "            \" \".join(reranked[\"text\"].tolist()[:ABSTRACTS_FOR_ANSWER]),\n",
    "        )\n",
    "    ] * len(df)\n",
    "\n",
    "    df.to_csv(\n",
    "        f\"temp/phase_b/answers/openai/abstracts/{df.questionno.values[0]}.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "\n",
    "IN_DIR = \"temp/phase_b/answers/openai/abstracts/\"\n",
    "\n",
    "for file in os.listdir(IN_DIR):\n",
    "    df = pd.read_csv(os.path.join(IN_DIR, file))\n",
    "    df[\"answer_abstracts_exact\"] = df[\"answer_abstracts_exact\"].apply(ast.literal_eval)\n",
    "    df[\"answer_abstracts_ideal\"] = df[\"answer_abstracts_ideal\"].apply(ast.literal_eval)\n",
    "\n",
    "    if df[\"questiontype\"].values[0] == \"summary\":\n",
    "        json_list.append(\n",
    "            {\n",
    "                \"type\": df[\"questiontype\"].values[0],\n",
    "                \"body\": df[\"question\"].values[0],\n",
    "                \"id\": df[\"questionno\"].values[0],\n",
    "                \"ideal_answer\": df[\"answer_abstracts_ideal\"].values[0][0],\n",
    "                \"documents\": df[\"documents\"].apply(ast.literal_eval).tolist()[0],\n",
    "                \"snippets\": df[\"snippets\"].apply(ast.literal_eval).tolist()[0],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        if df[\"questiontype\"].values[0] in (\"factoid\", \"list\"):\n",
    "            exact_answer = fix_list(df[\"answer_abstracts_exact\"].values[0])\n",
    "        else:\n",
    "            exact_answer = df[\"answer_abstracts_exact\"].values[0][0]\n",
    "\n",
    "        json_list.append(\n",
    "            {\n",
    "                \"type\": df[\"questiontype\"].values[0],\n",
    "                \"body\": df[\"question\"].values[0],\n",
    "                \"id\": df[\"questionno\"].values[0],\n",
    "                \"ideal_answer\": df[\"answer_abstracts_ideal\"].values[0][0],\n",
    "                \"exact_answer\": exact_answer,\n",
    "                \"documents\": df[\"documents\"].apply(ast.literal_eval).tolist()[0],\n",
    "                \"snippets\": df[\"snippets\"].apply(ast.literal_eval).tolist()[0],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    json_out = {\"questions\": json_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp/phase_b/submission/system_2.json\", \"w\") as f:\n",
    "    json.dump(json_out, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in json_list:\n",
    "#     print(d[\"body\"])\n",
    "#     try:\n",
    "#         print(d[\"exact_answer\"])\n",
    "#     except:\n",
    "#         print(\"NO ANSWER\")\n",
    "#     print(d[\"ideal_answer\"])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reranked[\"snippets_blablador_gpt\"] = reranked.apply(\n",
    "#     lambda x: get_snippets_blablador(\n",
    "#         question.body, x[\"title\"], x[\"text\"], model=\"gpt-3.5-turbo\"\n",
    "#     ),\n",
    "#     axis=1,\n",
    "# )\n",
    "# reranked[\"snippets_blablador_mistral\"] = reranked.apply(\n",
    "#     lambda x: get_snippets_blablador(\n",
    "#         question.body, x[\"title\"], x[\"text\"], model=\"Mistral-7B-Instruct-v0.2\"\n",
    "#     ),\n",
    "#     axis=1,\n",
    "# )\n",
    "# reranked[\"title_snippets_gpt\"] = [x[0] for x in reranked[\"snippets_blablador_gpt\"]]\n",
    "# reranked[\"abstract_snippets_gpt\"] = [\n",
    "#     x[1] for x in reranked[\"snippets_blablador_gpt\"]\n",
    "# ]\n",
    "# reranked[\"title_snippets_mistral\"] = [\n",
    "#     x[0] for x in reranked[\"snippets_blablador_mistral\"]\n",
    "# ]\n",
    "# reranked[\"abstract_snippets_mistral\"] = [\n",
    "#     x[1] for x in reranked[\"snippets_blablador_mistral\"]\n",
    "# ]\n",
    "\n",
    "# reranked[\"offset_title_gpt\"] = reranked.apply(\n",
    "#     lambda x: get_offset(x[\"title_snippets_gpt\"], x[\"text\"]), axis=1\n",
    "# )\n",
    "# reranked[\"offset_abstract_gpt\"] = reranked.apply(\n",
    "#     lambda x: get_offset(x[\"abstract_snippets_gpt\"], x[\"text\"]), axis=1\n",
    "# )\n",
    "\n",
    "# reranked[\"offset_title_mistral\"] = reranked.apply(\n",
    "#     lambda x: get_offset(x[\"title_snippets_mistral\"], x[\"text\"]), axis=1\n",
    "# )\n",
    "# reranked[\"offset_abstract_mistral\"] = reranked.apply(\n",
    "#     lambda x: get_offset(x[\"abstract_snippets_mistral\"], x[\"text\"]), axis=1\n",
    "# )\n",
    "\n",
    "\n",
    "# reranked[\"answer_abstracts_exact\"] = [\n",
    "#     response_exact_answer(\n",
    "#         question.body,\n",
    "#         question.type,\n",
    "#         \" \".join(reranked[\"text\"].tolist()[:ABSTRACTS_FOR_ANSWER]),\n",
    "#     )\n",
    "# ] * len(reranked)\n",
    "# reranked[\"answer_abstracts_ideal\"] = [\n",
    "#     response_ideal_answer(\n",
    "#         question.body,\n",
    "#         question.type,\n",
    "#         \" \".join(reranked[\"text\"].tolist()[:ABSTRACTS_FOR_ANSWER]),\n",
    "#     )\n",
    "# ] * len(reranked)\n",
    "# reranked[\"answer_snippets_exact\"] = [\n",
    "#     response_exact_answer(\n",
    "#         question.body,\n",
    "#         question.type,\n",
    "#         \" \".join(\n",
    "#             flat_list(reranked[\"abstract_snippets\"].tolist())\n",
    "#             + flat_list(reranked[\"title_snippets\"])\n",
    "#         ),\n",
    "#     )\n",
    "# ] * len(reranked)\n",
    "# reranked[\"answer_snippets_ideal\"] = [\n",
    "#     response_ideal_answer(\n",
    "#         question.body,\n",
    "#         question.type,\n",
    "#         \" \".join(\n",
    "#             flat_list(reranked[\"abstract_snippets\"].tolist())\n",
    "#             + flat_list(reranked[\"title_snippets\"])\n",
    "#         ),\n",
    "#     )\n",
    "# ] * len(reranked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
